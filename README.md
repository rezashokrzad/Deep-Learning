# Deep-Learning
Based on book d2l

Files contain:
1. File1:
  - Experiment with gradient descent optimization;
  - Derive and implement gradients for binary cross-entropy loss, the sigmoid function and a linear layer;
  - Test your gradient implementations with the finite difference method;
  - Use these components to implement and train a simple neural network.

2. File2:
  - Learn how to define and train a neural network with pytorch;
  - Experiment with convolutional neural networks;
  - Investigate the effect of dropout and batch normalization.

3. File3:
  - Implement an LSTM module from scratch;
  - Use the built-in LSTM module from PyTorch;
  - Compare fully connected and recurrent neural networks in an experiment;
  - Experiment with data augmentation.

4. File4: 
  - Train and modify a transformer network;
  - Experiment with a translation dataset.

5. File5:
  - Implement and train a generative adversarial network;
  - Experiment with reverse gradient training;
  - Implement a CycleGAN;
  - Experiment with CycleGAN optimization.








